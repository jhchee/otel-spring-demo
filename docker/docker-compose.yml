name: otel-demo
services:
  # Jaeger
  jaeger-all-in-one:
    image: jaegertracing/all-in-one:latest
    restart: always
    ports:
      - "16686:16686"
      - "14268"
      - "14250"

  # Zipkin
  zipkin-all-in-one:
    image: openzipkin/zipkin:latest
    environment:
      - JAVA_OPTS=-XX:UseSVE=0 -Xms1024m -Xmx1024m -XX:+ExitOnOutOfMemoryError
    restart: always
    ports:
      - "9411:9411"

  tempo:
    image: grafana/tempo:latest
    command: [ "-config.file=/etc/tempo.yaml" ]
    volumes:
      - ./tempo.yaml:/etc/tempo.yaml
      - ./tempo-data:/var/tempo
    ports:
#      - "14268:14268"  # jaeger ingest
      - "3200:3200"   # tempo
#      - "9095:9095" # tempo grpc
#      - "4317:4317"  # otlp grpc
#      - "4318:4318"  # otlp http
#      - "9411:9411"   # zipkin
    depends_on:
      - init
      - memcached

  memcached:
    image: memcached:1.6.29
    container_name: memcached
    ports:
      - "11211:11211"
    environment:
      - MEMCACHED_MAX_MEMORY=64m  # Set the maximum memory usage
      - MEMCACHED_THREADS=4       # Number of threads to use

  init:
    image: grafana/tempo:latest
    user: root
    entrypoint:
      - "chown"
      - "10001:10001"
      - "/var/tempo"
    volumes:
      - ./tempo-data:/var/tempo

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - ./grafana/automatic.yml:/etc/grafana/provisioning/datasources/tempo.yml
    environment:
      # Disable authentication
      - GF_AUTH_DISABLE_LOGIN_FORM=true
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_NAME=Main Org.
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_USERS_ALLOW_SIGN_UP=false

  # Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.114.0
    restart: always
    command: [ "--config=/etc/otel-collector-config.yaml", "${OTELCOL_ARGS}" ]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "1888:1888"   # pprof extension
      - "8888:8888"   # Prometheus metrics exposed by the collector
      - "8889:8889"   # Prometheus exporter metrics
      - "13133:13133" # health_check extension
      - "4318:4318"   # otlp receiver
      - "55679:55679" # zpages extension
    depends_on:
      - jaeger-all-in-one
      - zipkin-all-in-one

  prometheus:
    image: prom/prometheus:latest
    restart: always
    volumes:
      - ./prometheus.yaml:/etc/prometheus/prometheus.yml
    ports:
      - "10090:9090"

  postgres:
    image: postgres:17-alpine
    restart: always
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: postgres
    ports:
      - "5432:5432"

  localstack: # LocalStack container
    image: localstack/localstack:latest
    ports:
      # Map the port so you can access the API from the host machine
      - 4566:4566
    volumes:
      # Here you mount your setup file so it will be executed
      # when the container starts
      - ./localstack-setup.sh:/etc/localstack/init/ready.d/script.sh
  broker:
    image: confluentinc/cp-kafka:7.5.3
    networks:
      - otel-demo-network
    hostname: broker
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      # Endpoints
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_LISTENERS: 'PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      # Replications
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # JMX
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      # Kraft
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@broker:29093'
      # Misc
      KAFKA_NODE_ID: 1
      KAFKA_BROKER_ID: 1
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"
      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'

  init-kafka:
    image: confluentinc/cp-kafka:7.5.0
    networks:
      - otel-demo-network
    depends_on:
      - broker
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server broker:29092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server broker:29092 --create --if-not-exists --topic transaction-event --replication-factor 1 --partitions 2
      kafka-topics --bootstrap-server broker:29092 --create --if-not-exists --topic transfer-alert --replication-factor 1 --partitions 2

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server broker:29092 --list
      "

  kafka-ui:
    image: provectuslabs/kafka-ui:8f2a29d15ddbcb49675fef0e81cebc42cf2bebf3
    networks:
      - otel-demo-network
    ports:
      - '9090:8080'
    environment:
      DYNAMIC_CONFIG_ENABLED: 'true'
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker:29092
      KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM: PLAIN

networks:
  otel-demo-network: